{
 "metadata": {
  "name": "",
  "signature": "sha256:2b89da3d3caf9a832f6b1f98749d8869580b2ebb8ee7b8b87b3d96650a103950"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "# Fast Lomb-Scargle Periodograms in Python"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "*This notebook originally appeared as a [post](http://jakevdp.github.io/blog/2015/06/10/lomb-scargle-in-python/) on the blog [Pythonic Perambulations](http://jakevdp.github.io). The content is BSD licensed.*"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "<!-- PELICAN_BEGIN_SUMMARY -->\n",
      "\n",
      "<div style=\"float: right; margin-top: 10px; margin-bottom: 50px; width: 280px; height: 220px; margin: 10px;\">\n",
      "<center>\n",
      "<a href=\"http://www.astroml.org/_images/fig_LS_example_1.png\"><img src=\"http://www.astroml.org/_images/fig_LS_example_1.png\"></a>\n",
      "<small>Image source: astroML. Source code [here](http://www.astroml.org/book_figures/chapter10/fig_LS_example.html#book-fig-chapter10-fig-ls-example)</small>\n",
      "</center>\n",
      "</div>\n",
      "\n",
      "The Lomb-Scargle periodogram (named for [Lomb (1976)](http://adsabs.harvard.edu/abs/1976Ap%26SS..39..447L) and [Scargle (1982)](http://adsabs.harvard.edu/abs/1982ApJ...263..835S) is a classic method for finding periodicity in irregularly-sampled data.\n",
      "It is in many ways analogous to the more familiar Fourier Power Spectral Density (PSD) often used for detecting periodicity in regularly-sampled data.\n",
      "\n",
      "Despite the importance of this method, until recently there have not been any (in my opinion) solid implementations of the algorithm available for easy use in Python.\n",
      "That has changed with the introduction of the [gatspy](http://astroml.org/gatspy/) package, which I recently released.\n",
      "In this post, I will compare several available Python implementations of the Lomb-Scargle periodogram, and discuss some of the considerations required when using it to analyze data.\n",
      "\n",
      "To cut to the chase, I'd recommend using the [gatspy](http://astroml.org/gatspy/) package for Lomb-Scargle periodograms in Python, and particularly its ``gatspy.periodic.LombScargleFast`` algorithm which implements an efficient pure-Python version of Press & Rybicki's $O[N\\log N]$ periodogram.\n",
      "Below, I'll dive into the reasons for this recommendation.\n",
      "\n",
      "<!-- PELICAN_END_SUMMARY -->"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Example: Lomb-Scargle on Variable Stars\n",
      "\n",
      "As an example, let's quickly consider some data from my own field: observations of an [*RR Lyrae-type*](https://en.wikipedia.org/wiki/RR_Lyrae_variable) variable star.\n",
      "RR Lyrae are small stars which pulsate with a regular period on order half a day.\n",
      "Their relatively consistent peak intrinsic brightness allows for an accurate estimation of their distance from the sun, and thus they are important for studies such as [understanding the substructure](http://www.mpia.de/~bsesar/media.html) of the Milky Way galaxy.\n",
      "For this reason, detecting the telltale periodic variation of RR Lyrae stars is an important statistical task for astronomers.\n",
      "\n",
      "Here we will quickly demonstrate what this looks like in practice, using tools from the [astroML](http://astroML.org) package to download some data, and tools from the [gatspy](http://astroml.org/gatspy/) package to detect the periodicity.\n",
      "\n",
      "We'll start with some typical Python import statements:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Do preliminary imports and notebook setup\n",
      "%matplotlib inline\n",
      "import numpy as np\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "# use seaborn for plot styles\n",
      "import seaborn; seaborn.set()"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now we'll download some data from the [LINEAR](https://en.wikipedia.org/wiki/Lincoln_Near-Earth_Asteroid_Research) dataset, using tools in astroML.\n",
      "We'll plot the data to see what we're working with:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from astroML.datasets import fetch_LINEAR_sample\n",
      "LINEAR_data = fetch_LINEAR_sample()\n",
      "star_id = 10040133\n",
      "t, mag, dmag = LINEAR_data.get_light_curve(star_id).T\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "ax.errorbar(t, mag, dmag, fmt='.k', ecolor='gray')\n",
      "ax.set(xlabel='Time (days)', ylabel='magitude',\n",
      "       title='LINEAR object {0}'.format(star_id))\n",
      "ax.invert_yaxis();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This data has around 250 observations spread across about 2000 days, and we're hoping to detect a period of order 0.5 days.\n",
      "If the series were regularly-sampled, we'd be far above the Nyquist limit and all hope would be lost.\n",
      "Fortunately for astronomers, the assumptions behind the Nyquist sampling limit do not hold for irregular sampling rates, and we can proceed with no problem.\n",
      "\n",
      "Let's start by computing and plotting the Lomb-Scargle Periodogram for this data, using tools from gatspy:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gatspy.periodic import LombScargleFast\n",
      "model = LombScargleFast().fit(t, mag, dmag)\n",
      "periods, power = model.periodogram_auto(nyquist_factor=100)\n",
      "\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(periods, power)\n",
      "ax.set(xlim=(0.2, 1.4), ylim=(0, 0.8),\n",
      "       xlabel='period (days)',\n",
      "       ylabel='Lomb-Scargle Power');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The periodogram gives a measure of periodic content as a function of period; we see here a strong peak at around 0.61 days.\n",
      "Other lower peaks are due to some combination of higher-order harmonics in the data and effects of the irregular survey window.\n",
      "While we could find this maximum manually from the above grid, ``gatspy`` provides a better way: a built-in two-stage grid-search to accurately determine the best period in a specified range:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model.optimizer.period_range=(0.2, 1.4)\n",
      "period = model.best_period\n",
      "print(\"period = {0}\".format(period))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We see that the optimizer determined that it needed a grid of over 40,000 points to adequately cover the frequency grid, and in the end arrived at a best period of 0.61 days.\n",
      "Given this detected period, we can fold the input data and over-plot a best-fit RR Lyrae template to see the fit:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# Compute phases of the obsevations\n",
      "phase = (t / period) % 1\n",
      "\n",
      "# Compute best-fit RR Lyrae template\n",
      "from gatspy.periodic import RRLyraeTemplateModeler\n",
      "model = RRLyraeTemplateModeler('r').fit(t, mag, dmag)\n",
      "phase_fit = np.linspace(0, 1, 1000)\n",
      "mag_fit = model.predict(period * phase_fit, period=period)\n",
      "\n",
      "# Plot the phased data & model\n",
      "fig, ax = plt.subplots()\n",
      "ax.errorbar(phase, mag, dmag, fmt='.k', ecolor='gray', alpha=0.5)\n",
      "ax.plot(phase_fit, mag_fit, '-k')\n",
      "ax.set(xlabel='Phase', ylabel='magitude')\n",
      "ax.invert_yaxis();"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "This very close template fit gives a strong indication that the star in question is an RR Lyrae."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Computational Considerations for Lomb-Scargle\n",
      "\n",
      "The Lomb-Scargle periodogram involves the computation of a power $P(\\omega)$ at a set of frequencies $\\omega_i$.\n",
      "For data $\\{y_k\\}$ pre-centered such that $\\sum_k y_k = 0$, the expression for the power is:\n",
      "\n",
      "$$\n",
      "P(\\omega) \\propto\n",
      "  \\frac{\\left[\\sum_k y_k \\cos\\omega(t_k - \\tau)\\right]^2}\n",
      "    {\\sum_k \\cos^2\\omega(t_k - \\tau)} +\n",
      "  \\frac{\\left[\\sum_k y_k \\sin\\omega(t_k - \\tau)\\right]^2}\n",
      "    {\\sum_k \\sin^2\\omega(t_k - \\tau)}\n",
      "$$\n",
      "\n",
      "where $\\tau$ is an easily computed time-offset which orthogonalizes the model and makes $P(\\omega)$ independent of a translation in $t$.\n",
      "\n",
      "Rather than get lost in the math, I want to emphasize the key feature of this expression: **for any frequency $\\omega$, the power is an $O[N]$ computation involving simple trigonometric sums over the data.**\n",
      "The main computational question then becomes: how many frequencies must you compute?\n",
      "In my experience, the most common mistake people make when doing this sort of periodic analysis is not thinking hard enough about the frequency grid.\n",
      "It turns out that the grid-spacing question is *very* important.\n",
      "If you choose too narrow a grid, you do much more computation than is required.\n",
      "Worse, if you choose too wide a grid, the periodogram peak may fall between grid points and you'll miss it entirely!\n",
      "\n",
      "Let's think about the required frequency range and frequency spacing for Lomb-Scargle."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Frequency spacing\n",
      "\n",
      "First we'll choose the spacing of the frequency grid.\n",
      "If you're asking about a candidate frequency $f$, then data with range $T = t_{max} - t_{min}$ contains $T \\cdot f$ complete cycles. If our error in frequency is $\\delta f$, then $T\\cdot\\delta f$ is the error in number of cycles between the endpoints of the data.\n",
      "It's clear that this error must not be a significant fraction of a cycle, or the fit could be drastically affected.\n",
      "This leads to an approximate grid-spacing criterion:\n",
      "\n",
      "$$\n",
      "T\\cdot\\delta f \\ll 1\n",
      "$$\n",
      "\n",
      "Commonly, we'll choose some oversampling factor (say, 5) and use $\\delta f = (5T)^{-1}$ as our frequency grid spacing."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Frequency limits\n",
      "\n",
      "Next, we need to choose the upper and lower limits of the frequency grid. On the low end, $f=0$ is suitable, but causes some numerical problems \u2013 we'll go one step away and use $\\delta f$ as our minimum frequency.\n",
      "But on the high end, we need to make a choice: what's the highest frequency we'd trust our data to be sensitive to?\n",
      "At this point, many people are tempted to mis-apply the Nyquist-Shannon sampling theorem, and choose some version of the Nyquist limit for the data (based on, say, the minimum or mean spacing between observations).\n",
      "But this is entirely wrong! The Nyquist frequency is derived from special properties of regularly-sampled data, and does not even approximately apply to irregularly-sampled time-series.\n",
      "In fact, as we saw above, irregularly-sampled data can be sensitive to much, much higher frequencies than even the minimum spacing between observations.\n",
      "With this in mind, the upper limit for frequencies should be determined based on **what kind of signals you are looking for.**\n",
      "\n",
      "Still, a common rule-of-thumb is that the high frequency is some multiple of what Press & Rybicki call the \"average\" Nyquist frequency,\n",
      "\n",
      "$$\n",
      "\\hat{f}_{Ny} = \\frac{N}{2T}\n",
      "$$\n",
      "\n",
      "This means that the \"typical\" number of frequencies you'll need is\n",
      "\n",
      "$$\n",
      "N_{freq} \\approx \\frac{\\hat{f}_{Ny}}{\\delta f} \\approx \\frac{N/(2T)}{1/(5T)} \\propto N\n",
      "$$\n",
      "\n",
      "That is, the number of frequencies to search will scale with the number of data points!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Computational Complexity\n",
      "\n",
      "From the above considerations, we see that the determination of the optimal Lomb-Scargle period within $N$ points requires computing an $O[N]$ expression for power across $O[N]$ grid points; that is, Lomb-Scargle is naively an $O[N^2]$ algorithm.\n",
      "\n",
      "This computational complexity can be improved in one of several ways.\n",
      "Most notably, in a [1989 paper](http://adsabs.harvard.edu/full/1989ApJ...338..277P), Press and Rybicki proposed a clever method whereby a Fast Fourier Transform is used on a grid *extirpolated* from the original data, such that this naively $O[N^2]$ problem can be solved in $O[N\\log N]$ time.\n",
      "The broad idea is that when you compute sums of sines and cosines for one frequency, this gives you some amount of information about those sums computed at another frequency, and by carefully using all information across a frequency grid, you can significantly reduce the number of required operations. In practice, Press & Rybicki showed that this can be accomplished by using a Fast Fourier Transform across a carefully \"extirpolated\" grid.\n",
      "\n",
      "Thus the fundamental divide between Lomb-Scargle implementations is whether they use the naive $O[N^2]$ algorithm or the $O[N\\log N]$ algorithm of Press & Rybicki and other similar approaches."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Lomb-Scargle Algorithms in Python\n",
      "\n",
      "Now we get to the meat of this post: Lomb-Scargle implementations written in Python.\n",
      "If you search this on Google, you'll currently find links to several available implementations.\n",
      "Here I'm going to delve into and compare the following four implementations:\n",
      "\n",
      "- ``scipy.signal.lombscargle``, an $O[N^2]$ implementation from [SciPy].(http://docs.scipy.org/doc/scipy/reference/)\n",
      "- ``astroML.time_series.lomb_scargle``, an $O[N^2]$ implementation from [astroML].(http://astroML.org/)\n",
      "- ``gatspy.periodic.LombScargle``, an $O[N^2]$ implementation from [gatspy].(http://astroml.org/gatspy/)\n",
      "- ``gatspy.periodic.LombScargleFast``, an $O[N\\log N]$ implementation, also from [gatspy].(http://astroml.org/gatspy/)\n",
      "\n",
      "Other implementations are floating about which I won't discuss in detail, but I will mention briefly here:\n",
      "\n",
      "- This [AstroPython Lomb Scargle snippet](http://www.astropython.org/snippet/2010/9/Fast-Lomb-Scargle-algorithm) is a pure-python version of the original $O[N\\log N]$ Fortran implementation of the [Press & Rybicki](http://adsabs.harvard.edu/abs/1989ApJ...338..277P) algorithm; doing such low-level operations in Python rather than in numpy or Fortran results in a painfully slow algorithm.\n",
      "- [pynfftls](https://pypi.python.org/pypi/pynfftls/) implements an $O[N\\log N]$ Lomb-Scargle based on the NUFFT algorithm, which I discussed in a [previous post](https://jakevdp.github.io/blog/2015/02/24/optimizing-python-with-numpy-and-numba/). Though the package is likely very fast, it requires manual linking to several compiled libraries.\n",
      "For better or worse, in the world of [conda](http://www.continuum.io/blog/conda) I no longer have the patience for such installation headaches, especially when alternative packages can be set up with a simple ``pip install``. But for pure computational speed, I suspect this tool will win-out.\n",
      "\n",
      "Let's see some examples of the above tools:"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ``scipy.signal.lombscargle``\n",
      "\n",
      "The SciPy Lomb-Scargle periodogram is a C implementation of the naive $O[N^2]$ algorithm.\n",
      "The algorithm cannot account for noise in the data, and has some other quirks as well:\n",
      "\n",
      "- it requires you to center your data before computing the periodogram. If you do not, the results will be garbage.\n",
      "- it computes the unnormalized periodogram, which can be normalized as we'll see below.\n",
      "- it takes *angular frequencies* as the argument\n",
      "\n",
      "Let's use this to plot the periodogram of the data shown above.\n",
      "Note that the results will not be identical, because this algorithm ignores the noise in the data.\n",
      "\n",
      "Against the above recommendations, we'll choose a simple regular grid in period for the plot:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.signal import lombscargle\n",
      "\n",
      "# Choose a period grid\n",
      "periods = np.linspace(0.2, 1.4, 4000)\n",
      "ang_freqs = 2 * np.pi / periods\n",
      "\n",
      "# compute the (unnormalized) periodogram\n",
      "# note pre-centering of y values!\n",
      "power = lombscargle(t, mag - mag.mean(), ang_freqs)\n",
      "\n",
      "# normalize the power\n",
      "N = len(t)\n",
      "power *= 2 / (N * mag.std() ** 2)\n",
      "\n",
      "# plot the results\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(periods, power)\n",
      "ax.set(ylim=(0, 0.8), xlabel='period (days)',\n",
      "       ylabel='Lomb-Scargle Power');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Comparing to the first periodogram plot, we see that becuase our period grid here is too coarse at low frequencies, some of the peak structure is missed by this visualization.\n",
      "Consider this a warning against arbitrarily choosing a period gridding!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ``astroML.time_series.lomb_scargle``\n",
      "\n",
      "AstroML has two $O[N^2]$ implementations of Lomb-Scargle: one in ``astroML`` and one in ``astroML_addons``, which is a collection of C extensions which replace slower functionality in the pure-python astroML package.\n",
      "In order to use the faster version, make sure you install both packages; e.g.\n",
      "\n",
      "```\n",
      "$ pip install astroML\n",
      "$ pip install astroML_addons\n",
      "```\n",
      "\n",
      "Some important features of astroML's Lomb Scargle periodogram:\n",
      "\n",
      "- unlike scipy, it uses an extended periodogram model which can correctly account for uncorrelated Gaussian measurement error\n",
      "- like scipy, it takes *angular frequencies* as its argument\n",
      "- unlike scipy, it implements a *floating mean periodogram*, meaning that the data centering required for scipy is not required here, but it goes beyond simple centering: the mean of the data is fit *as part of the model*, which has advantages in many real-world scenarios. To directly compare to scipy's standard Lomb Scargle pass ``generalized=False``.\n",
      "\n",
      "Let's repeat the above plot with this periodogram:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from astroML.time_series import lomb_scargle\n",
      "power = lomb_scargle(t, mag, dmag, ang_freqs)\n",
      "\n",
      "# plot the results\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(periods, power)\n",
      "ax.set(ylim=(0, 0.8), xlabel='period (days)',\n",
      "       ylabel='Lomb-Scargle Power');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ``gatspy.periodic.LombScargle``\n",
      "\n",
      "Gatspy's basic Lomb-Scargle algorithm is an $O[N^2]$ implementation, but is implemented differently than either of the above versions.\n",
      "It uses a direct linear algebra approach which has some additional computational and memory overhead.\n",
      "The reason for this approach is that it naturally accommodates several extensions to the periodogram, including floating mean, multiple terms, regularization, and multi-band models (more details in [VanderPlas & Ivezic (2015)](http://adsabs.harvard.edu/abs/2015arXiv150201344V), the paper that inspired ``gatspy``).\n",
      "\n",
      "Gatspy is a pure python package, and thus installation is easy and requires no compilation of C or Fortran code:\n",
      "\n",
      "```\n",
      "$ pip install gatspy\n",
      "```\n",
      "\n",
      "Some important features of this implementation:\n",
      "\n",
      "- like astroML, it uses an extended periodogram model which correctly accounts for uncorrelated Gaussian measurement error\n",
      "- unlike astroML, it takes *periods* as its argument\n",
      "- like astroML, it uses a floating mean model by default. To compare directly to scipy's non-floating-mean model, set ``fit_offset=False``\n",
      "- it has an API inspired by scikit-learn, where the **model specification** is a class instance, the model is applied to data with a ``fit()`` method, and the periodogram is computed via a ``score()`` method.\n",
      "\n",
      "Let's repeat the above periodogram using this tool:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gatspy.periodic import LombScargle\n",
      "\n",
      "model = LombScargle(fit_offset=True).fit(t, mag, dmag)\n",
      "power = model.score(periods)\n",
      "\n",
      "# plot the results\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(periods, power)\n",
      "ax.set(ylim=(0, 0.8), xlabel='period (days)',\n",
      "       ylabel='Lomb-Scargle Power');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "#### ``gatspy.periodic.LombScargleFast``\n",
      "\n",
      "Gatspy's fast Lomb-Scargle is an $O[N\\log N]$ algorithm built on a pure Python/numpy implementation of the Press & Rybicki FFT/extirpolation method.\n",
      "Note that a requirement of this fast algorithm is that it be computed on a regular grid of *frequencies* (not periods), and so to attain this performance it provides the ``score_frequency_grid()`` method which takes 3 arguments: the minimum frequency ``f0``, the frequency spacing ``df``, and the number of grid points ``N``.\n",
      "\n",
      "Some features of the model\n",
      "\n",
      "- like astroML, it uses an extended periodogram model which correctly accounts for uncorrelated Gaussian measurement error\n",
      "- it takes *a regular frequency grid* as its argument for the fast computation; note that the ``score()`` function itself falls back on the slower ``LombScargle`` approach above.\n",
      "- like astroML, it uses a floating mean model by default. To compare directly to scipy, set ``fit_offset=False``\n",
      "- it has an identical API to the ``LombScargle`` object above.\n",
      "\n",
      "Let's take a look at computing the periodogram:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from gatspy.periodic import LombScargleFast\n",
      "\n",
      "fmin = 1. / periods.max()\n",
      "fmax = 1. / periods.min()\n",
      "N = 10000\n",
      "df = (fmax - fmin) / N\n",
      "\n",
      "model = LombScargleFast().fit(t, mag, dmag)\n",
      "power = model.score_frequency_grid(fmin, df, N)\n",
      "freqs = fmin + df * np.arange(N)\n",
      "\n",
      "# plot the results\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(1. / freqs, power)\n",
      "ax.set(ylim=(0, 0.8), xlabel='period (days)',\n",
      "       ylabel='Lomb-Scargle Power');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "You'll notice here that this approach shows a lot more high-frequency peaks than any of the above versions.\n",
      "This is not because it is computing a different model; it is because we are using a finer frequency grid which does not miss these peaks.\n",
      "The above versions, with a regular grid of 4000 periods *miss these important features*, and give the user absolutely no warning that these features are missed!\n",
      "Keep this in mind as you choose grid parameters while following the above discussion.\n",
      "\n",
      "If you want to make sure you're using a sufficient grid, you can use the ``periodogram_auto()`` method of ``LombScargleFast``, which computes a sufficient frequency grid for you using the rules-of-thumb discussed above:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "model = LombScargleFast().fit(t, mag, dmag)\n",
      "\n",
      "period, power = model.periodogram_auto(nyquist_factor=200)\n",
      "\n",
      "print(\"period range: ({0}, {1})\".format(period.min(), period.max()))\n",
      "print(\"number of periods: {0}\".format(len(period)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The model decided that we needed over 100,000 periods, between about 0.1 days (which was tuned by the ``nyquist_factor`` argument) and about 10,000 days (which is derived from the time-span of the data). Plotting the results as above, we see a similar periodogram:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# plot the results\n",
      "fig, ax = plt.subplots()\n",
      "ax.plot(period, power)\n",
      "ax.set(xlim=(0.2, 1.4), ylim=(0, 1.0),\n",
      "       xlabel='period (days)',\n",
      "       ylabel='Lomb-Scargle Power');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The ``LombScargleFast`` algorithm computes these $10^5$ periodogram steps very quickly; I wouldn't suggest any of the other methods with a grid of this size!"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Benchmarking Lomb-Scargle Implementations\n",
      "\n",
      "As a final piece of the picture, let's compare the execution speed of the four approaches.\n",
      "We can do this with IPython's ``%timeit`` magic function using the following script.\n",
      "Note that this script will take several minutes to run, as it automatically does multiple passes of each benchmark to minimize system timing variation.\n",
      "For efficiency, we cut-off the slower algorithms at high $N$:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "from scipy.signal import lombscargle as ls_scipy\n",
      "from astroML.time_series import lomb_scargle as ls_astroML\n",
      "\n",
      "def create_data(N, rseed=0, period=0.61):\n",
      "    \"\"\"Create noisy data\"\"\"\n",
      "    rng = np.random.RandomState(rseed)\n",
      "    t = 52000 + 2000 * rng.rand(N)\n",
      "    dmag = 0.1 * (1 + rng.rand(N))\n",
      "    mag = 15 + 0.6 * np.sin(2 * np.pi * t / period) + dmag * rng.randn(N)\n",
      "    return t, mag, dmag\n",
      "\n",
      "def compute_frequency_grid(t, oversampling=2):\n",
      "    \"\"\"Compute the optimal frequency grid (**not** angular frequencies)\"\"\"\n",
      "    T = t.max() - t.min()\n",
      "    N = len(t)\n",
      "    df = 1. / (oversampling * T)\n",
      "    fmax = N / (2 * T)\n",
      "    return np.arange(df, fmax, df)\n",
      "\n",
      "Nrange = 2 ** np.arange(2, 17)\n",
      "t_scipy = []\n",
      "t_astroML = []\n",
      "t_gatspy1 = []\n",
      "t_gatspy2 = []\n",
      "\n",
      "for N in Nrange:\n",
      "    t, mag, dmag = create_data(N)\n",
      "    freqs = compute_frequency_grid(t)\n",
      "    periods = 1 / freqs\n",
      "    ang_freqs = 2 * np.pi * freqs\n",
      "    f0, df, Nf = freqs[0], freqs[1] - freqs[0], len(freqs)\n",
      "    \n",
      "    # Don't compute the slow algorithms at very high N\n",
      "    if N < 2 ** 15:\n",
      "        t1 = %timeit -oq ls_scipy(t, mag - mag.mean(), ang_freqs)\n",
      "        t2 = %timeit -oq ls_astroML(t, mag, dmag, ang_freqs)\n",
      "        t3 = %timeit -oq LombScargle().fit(t, mag, dmag).score_frequency_grid(f0, df, Nf)\n",
      "        t_scipy.append(t1.best)\n",
      "        t_astroML.append(t2.best)\n",
      "        t_gatspy1.append(t3.best)\n",
      "    else:\n",
      "        t_scipy.append(np.nan)\n",
      "        t_astroML.append(np.nan)\n",
      "        t_gatspy1.append(np.nan)\n",
      "        \n",
      "    t4 = %timeit -oq LombScargleFast().fit(t, mag, dmag).score_frequency_grid(f0, df, Nf)\n",
      "    t_gatspy2.append(t4.best)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "When these timings are finished, we can plot the results to get an idea of how the algorithms compare:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "fig = plt.figure()\n",
      "ax = fig.add_subplot(111, xscale='log', yscale='log')\n",
      "ax.plot(Nrange, t_scipy, label='scipy: lombscargle')\n",
      "ax.plot(Nrange, t_astroML, label='astroML: lomb_scargle')\n",
      "ax.plot(Nrange, t_gatspy1, label='gatspy: LombScargle')\n",
      "ax.plot(Nrange, t_gatspy2, label='gatspy: LombScargleFast')\n",
      "ax.set(xlabel='N', ylabel='time (seconds)',\n",
      "       title='Comparison of Lomb-Scargle Implementations')\n",
      "ax.legend(loc='upper left');"
     ],
     "language": "python",
     "metadata": {},
     "outputs": []
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Each model has a characteristic performance curve:\n",
      "\n",
      "- The **scipy** and **astroML** algorithms show similar behavior: fast $O[1]$ scaling at the small-$N$ limit, and clear $O[N^2]$ scaling at the large-$N$ limit. SciPy is slightly faster, primarily due to the fact that it computes the simpler, non-floating-mean/no error model.\n",
      "- Gatspy's ``LombScargle`` also becomes $O[N^2]$ at large $N$, but is dominated at small $N$ by an $O[N]$ contribution which comes from building the matrices associated with its linear algebraic approach. As $N$ grows larger than $\\sim 10^4$, however, gatspy's model begins to beat the performance of the other two $O[N^2]$ algorithms.\n",
      "- Gatspy's ``LombScargleFast`` has an upfront $O[1]$ cost that makes it slower than other approaches at small $N$, but as $N$ grows its $O[N\\log N]$ scaling means it dominates the performance of the other approaches by orders of magnitude."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Conclusion\n",
      "\n",
      "If there's anything I want you to take from the above discussion, it's these three points:\n",
      "\n",
      "- Naive application of Nyquist-style limits to irregularly-sampled data will cause you problems. Don't be the next person to make the mistake of assuming they do!\n",
      "- Choosing period/frequency grids for Lomb-Scargle analysis should not be taken lightly. It's very easy to create too-coarse of a grid, and miss important peaks!\n",
      "- Use ``gatspy.periodic.LombScargleFast`` if you want to compute a fast, $O[N\\log N]$ Lomb-Scargle periodogram in Python.\n",
      "\n",
      "Finally, I should mention that if even ``LombScargleFast`` proves too slow for you, check out some of the available implementations based on the NUFFT.\n",
      "While their packaging (and code licensing) could use some work, my own experiments show that these will be about a factor of 10 faster than ``LombScargleFast``, with similar scaling in $N$.\n",
      "\n",
      "Happy coding!\n",
      "\n",
      "<small>\n",
      "This post was written entirely in the IPython notebook.  You can\n",
      "[download](http://jakevdp.github.io/downloads/notebooks/LombScarglePython.ipynb)\n",
      "this notebook, or see a static view\n",
      "[here](http://nbviewer.ipython.org/url/jakevdp.github.io/downloads/notebooks/LombScarglePython.ipynb).\n",
      "</small>"
     ]
    }
   ],
   "metadata": {}
  }
 ]
}